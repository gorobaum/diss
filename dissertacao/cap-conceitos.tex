%% ------------------------------------------------------------------------- %%
\chapter{Conceitos}
\label{cap:conceitos}

%% ------------------------------------------------------------------------- %%
\section{Registro}\index{Registro}
\label{sec:fundamentos}

    O registro de imagens tem como objetivo encontrar um alinhamento entre duas imagens diferentes. Dada duas imagens, 
a imagem Referência (R) e a imagem Alvo (A), os algoritmos de registro encontram um campo
vetorial de deslocamento que é aplicado a imagem Alvo, movendo seus pixels para um estado no qual ela esteja alinhada
com a imagem Referência. Para encontrar um alinhamento, supomos que a imagem Alvo sofreu algum tipo de deformação,
e queremos, dado algum modelo que aproxime a deformação, encontrar os parâmetros para uma função de
transformação que nos leve da imagem Alvo para a imagem Registrada, que nada mais é que a imagem Alvo alinhada a imagem
Referência.

Podemos definir o processo de registro com a seguinte equação, como \cite{brown1992survey} fez em seu estudo:
\begin{align}\label{eq:defregistro}
    R(x,y) = g(A(f(x,y)))
\end{align}
    Representamos uma imagem como uma matriz de pixels e acessamos seus pixels utilizando a seguinte convenção $R(x,y)$ 
que nos dá o pixel da imagem $R$ na posição $(x,y)$. $f(x,y) = (x',y')$ é uma função que representa o deslocamento do 
campo vetorial encontrado pelo registro e $g$ é uma função que modifica a intensidade dos pixels, se for necessário.
Cada algoritmo de registro utiliza um método diferente para encontrar a função de transformação $f$, mas os passos gerais são:
\begin{enumerate}
    \item Pré-processamento;
    \item Detecção de características;
    \item Correspondência de características;
    \item Estimativa da função de transformação;
    \item Reamostragem da imagem Alvo.
\end{enumerate} % TODO: Colocar o diagrama aqui %
    É importante salientar que nem todos algoritmos de registro seguem essa lista a risca, e mesmo que sigam eles ainda
podem realizar mais de um passo por vez. Os passos gerais são representados na imagem \ref{fig:regExplicacao}. 
Vamos tratar brevemente dos passos nas seções a seguir, explicitando em alguns pontos onde os passos podem ser acelerados,
principalmente pela paralelização de suas operações.

\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.3\textwidth}
      \includegraphics[width=\textwidth]{figuras/static.png}
      \subcaption*{(a)}
      \label{fig:ref-image}
    \end{subfigure}
    \begin{subfigure}[t]{0.3\textwidth}
      \includegraphics[width=\textwidth]{figuras/leiaMoving.png}
      \subcaption*{(b)}
      \label{fig:sin-image}
    \end{subfigure} \\
    \begin{subfigure}[t]{0.64\textwidth}
      \includegraphics[width=\textwidth]{figuras/Features.png}
      \subcaption*{(c)}
      \label{fig:dist-image}
    \end{subfigure} \\
    \begin{subfigure}[t]{0.64\textwidth}
      \includegraphics[width=\textwidth]{figuras/MatchedFeatures.png}
      \subcaption*{(d)}
      \label{fig:dist-image}
    \end{subfigure} \\
    \begin{subfigure}[t]{0.3\textwidth}
      \includegraphics[width=\textwidth]{figuras/estimativa.png}
      \subcaption*{(e)}
      \label{fig:dist-image}
    \end{subfigure} 
    \begin{subfigure}[t]{0.3\textwidth}
      \includegraphics[width=\textwidth]{figuras/leiaRegistrada.png}
      \subcaption*{(f)}
      \label{fig:dist-image}
    \end{subfigure}
    \caption{(a) imagem Referência. (b) imagem Alvo deformada pela função seno. 
             (c) Detecção de características. (d) Correspondência de características.
             (e) Estimativa da função de transformação. (f) Reamostragem da imagem Alvo.}
    \label{fig:regExplicacao}
\end{figure}

%% ------------------------------------------------------------------------- %%
\subsection{Pré-processamento}
    Essa é a etapa mais aberta dentre todas, já que sua aplicação é totalmente dependente do problema a ser resolvido. 
Antes de iniciar o processo de registro, é possível que as imagens tenham que passar por algum processamento para 
melhorar o resultado final do registro. O pré-processamento muda de acordo com as necessidades de cada caso. Caso as
imagens tenham muito ruído, essa é a hora de aplicar filtros para melhorar sua qualidade, como um filtro Passa Alta ou 
o Passa Baixa. Certos algoritmos de registro não trabalham com as imagens, e sim com segmentações delas ou somente com 
suas bordas, então é necessário aplicar algoritmos como o \textit{Watershed}, introduzido por \cite{vincent1991watersheds}
ou o \textit{Canny}, desenvolvido por \cite{canny1986computational}, para obter as segmentações e bordas, respectivamente.

%% ------------------------------------------------------------------------- %%
\subsection{Detecção de características}\index{Detecção de características}
\label{sec:dec_corr_carac}

    Com as imagens já pré-processadas, o primeiro passo para um algoritmo de registro é a localização de estruturas de 
destaque na cena ou objeto dentro das imagens. Essas estruturas são nomeadas de características, e são construidas a partir
de um conjunto de pixels. Características devem ser facilmente identificadas, independente de variações na aquisição das 
fotografias, como mudanças na angulação ou perspectiva. Elas são separadas em 3 grupos, baseando-se nas suas propriedades:

\textbf{Características de Região} - As características de Região são áreas de uma imagem que apresentam uma diferença
significativa de contraste em relação a áreas vizinhas. Lagos, florestas ou regiões urbanas são exemplos desse tipo de 
característica. Elas são identificadas utilizando algoritmos de segmentação, e normalmente são representadas por um
conjunto conexo de pixels ou utilizando um \textit{template} de formato retângular ou circular centrado no centro de 
massa da Região.

\textbf{Características de Retas} - Essas características são definidas como a interface entre duas regiões de uma imagem,
comumente chamadas de bordas. Exemplos comuns de características de Reta são ruas, rios ou o litoral, onde podemos 
claramente visualizar a diferença de intensidade, por exemplo, do mar e da areia. Métodos clássicos de detecção de bordas 
como o Canny ou o filtro laplaciano são usados para identificar essas características.

\textbf{Características de Ponto} - São pontos de intersecção entre linhas, representados por intersecções de ruas ou
rios, ou pontos de máxima curvatura. Algoritmos para identificação de pontos utilizam técnicas mais avançadas, dada a 
dificuldade de encontrá-los. Os mais básicos encontram as intersecções de linhas enquanto os mais avançados buscam
centroides de regiões ou o máximo local de uma \textit{wavelet}.

    Dada a importância desse passo, vários algoritmos foram desenvolvidos com o passar dos anos para resolver de maneira
rápida e eficiente a detecção de características. Alguns dos mais famosos, como o 
\textit{Scale Invariant Feature Transform} (SIFT) , introduzido por \cite{lowe1999object}, transforma uma imagem em uma 
coleção de vetores de características locais, que são usados para identificá-las. Outro algoritmo famoso,
desenvolvido por \cite{bay2006surf}, o \textit{Speeded Up Robust Features} (SURF) utiliza o determinante da matriz de
Hessian para identificar regiões da imagem que tenham um valor diferenciado para alguma propriedade, como brilho, de 
regiões vizinhas. Ao identificar uma região, ele calcula a característica dela utilizando a soma dos 
\textit{Wavelets de Haar}.

    A verificação de existência de característica em um pixel não interfere na verificação em quaisquer outro pixel da
imagem, já que não precisamos modificar a imagem em nenhuma maneira. Uma simples paralelização do processamento já o
acelera.

%% ------------------------------------------------------------------------- %%
\subsection{Correspondência de características}\index{Correspondência de características}

    Com as características de cada uma das imagens encontradas, o próximo passo é realizar a correspondência entre elas.
A função desse passo é encontrar a correspondência entre pontos da imagem Referência para a imagem Alvo, ou vice-versa. 
O processo pode ser realizado tanto escolhendo ponto a ponto da imagem Referência e procurando o ponto com maior valor 
de proximidade entre os pontos da imagem Alvo, quanto utilizando métodos estatísticos para determinar quais pontos são 
correspondentes entre as duas imagens. É importante que esse passo consiga identificar pontos físicos, com coordenadas, 
em cada par de características, para que uma primeira estimativa dos parâmetros da função de transformação possa ser 
utilizada como ponto de partida para o próximo passo.

    A primeira solução a ser apresentada, a \textbf{Correspondência por Área}, mescla o passo de Detecção com o de 
Correspondência. Esse método utiliza duas janelas, uma em cada imagem, com formato retangular ou circular, aplicando
métricas em cada uma das janelas com a finalidade de calcular a relação entre as janelas. O algoritmo segue realizando
esse cálculo para todas as combinações possíveis de janelas entre as duas imagens, e sempre que um máximo é encontrado
o centro das janelas são usados para marcar a correspondência. Várias métricas podem ser utilizadas, como a 
Correlação entre as intensidades das janelas, o estudo do espectro da transformada de \textit{Fourier} das janelas ou 
o cálculo da informação mútua entre elas.

    A descoberta de correspondência entre \textbf{Características de Região} é feita utilizando, principalmente, duas 
técnicas. A primeira, mais simples na sua ideia, é parear regiões da imagem Referência com a região da imagem Alvo a qual
tenha o contorno mais parecido possível. Os métodos que fazem esse pareamento devem ser capazes de encontrar os pares mesmo
que eles tenham sofrido rotações ou mudança de escala. Descritores de Fourier e representações matriciais das regiões são
exemplos de métodos usados para realizar a correspondência entre características de região.

    Os métodos para encontrar correspondências entre \textbf{Características de Retas} tem as mesmas restrições que os
de Região, ou seja, devem conseguir realizar o pareamento de linhas que sofreram rotação, mudança de escala ou translação.
O primeiro passo de um algoritmo é comparar as retas da imagem Referência com todas as possíveis rotações de todas as retas
da imagem Alvo. Quando um possível par é encontrado, um valor de correspondência é calculado, utilizando um peso maior para
a direção da reta, algo que não sofre tanta influência de ruído, e um peso menor para atributos como comprimento e largura,
que são influenciados pelo ruído. O algoritmo ainda deve ser capaz de parear mais de duas retas por vez, dada a possibilidade
de uma reta em uma das imagens ser representada por duas retas na outra imagem.

    Por fim, as correspondências entre \textbf{Características de Ponto} podem ser encontradas utilizando-se várias técnicas
distintas. Como o número e o agrupamento de pontos geralmente não muda tanto com rotações e translações de imagens, métodos de 
\textit{Clustering} são usados para parear pontos. Os \textit{Clusters} são montados com base na proximidade dos parâmetros
de uma transformação que leve pontos da imagem Alvo para pontos da imagem Referência. Outro método define as características
através de descritores invariantes que podem obedecer a 4 regras: \textbf{Invariância}, características correspondentes 
devem ter os mesmos descritores; \textbf{Unicidade}, características diferentes devem ter descritores diferentes; 
\textbf{Estabilidade}, os descritores devem deformar de maneira proporcional a deformação aplicada na imagem; e 
\textbf{Independência}, se o descritor for representado por um vetor, seus componentes devem ser independentes. 
O que define um descritor deve ser decidido caso a caso. O modelo mais simples usado é a propria intensidade do pixel, 
e a intensidade de seus vizinhos. Outros descritores válidos são ângulos entre correspondências vizinhas ou a distribuição
espacial dos vizinhos.

    Podemos separar os algoritmos de correspondências em dois tipos com base no estilo com que eles fazem a busca de 
correspondências. O primeiro tipo escolhe uma correspondência na imagem Referência e realiza uma busca em largura por
todas as correspondências da imagem Alvo, buscando aquela com maior relação com a da imagem Referência. Esse processo
pode ser facilmente acelerado utilizando uma paralelização com todas as correspondências da imagem Referência. Já o outro
tipo realiza uma busca entre as relações das características e encontra os pares de maneira iterativa. A aceleração
desse passo depende totalmente da sua implementação.

    O modelo \textit{MapReduce} apresenta uma outra alternativa para acelerar esse passo e o anterior. Ele foi 
desenvolvido por \cite{dean2008mapreduce} e pela Google. O modelo \textit{MapReduce} foi desenvolvido para realizar 
processamento em lote de um número gigantesco de dados, o popular \textit{Big Data}, dado que não exista muita diferença 
em como os dados devem ser processados. Seu modelo de programação contém duas etapas principais, o \textit{Map}, que 
recebe um par de dados e retorna um par de valor/chave. Um passo intermediário agrupa todos os valores com mesma chave e
a lista resultante é enviada para o próximo passo, o \textit{Reduce}, onde a lista é processada. O nosso \textit{Map} 
recebe uma imagem Alvo e Referência, e encontra as características delas, enquanto o processo de agrupamento encontra as
suas correspondências. O \textit{Reduce} fica com qualquer etapa de pós-processamento, se necessário.
%% ------------------------------------------------------------------------- %%
\subsection{Estimativa da função de transformação}\index{Estimativa da função de transformação}
    
Com o conjunto de correspondências encontrado pelo passo anterior, os algoritmos de registro tem uma base para 
começar o processo de estimativa da função de transformação. Cada algoritmo assume um modelo de transformação diferente
para a deformação que a imagem sofreu, como por exemplo, uma modelagem elástica, por propagação de fluidos ou uma
simples translação. Juntando a modelagem com as correspondências, os algoritmos conseguem estimar parâmetros iniciais
para a função de transformação. Utilizando alguma métrica para passear pelo espaço de parâmetros, os algoritmos encontram
algum conjunto de parâmetros que alinhe a imagem Alvo com a imagem Referência. Na seção \ref{sec:algReg}, apresentaremos
dois algoritmos estudados com enfase nessa etapa.

%% ------------------------------------------------------------------------- %%
\subsection{Reamostragem da imagem Alvo}\index{Reamostragem da imagem Alvo}

O último passo do registro é a montagem da imagem Registrada, ou a reamostragem da imagem Alvo. O passo anterior
dá um conjunto de parâmetros para a montagem da imagem final, logo esse passo tem como objetivo a aplicação
da transformação $f$ utilizando os parâmetros encontrados sob todas as posições da imagem Alvo. Temos:

\begin{align}\label{eq:reamostragem}
    F(x_i,y_j) = A(f_o(x_i,y_j))), \forall (i = 1, \dots, n_c), (j = 1, \dots, n_l)
\end{align}

    Onde $F(x_i,y_j)$ representa a posição $(x_i,y_j)$ da imagem Registrada e $f_o$ é a função $f$ sob os parâmetros
encontrados no passo anterior.

%% ------------------------------------------------------------------------- %%
%% ------------------------------------------------------------------------- %%
\section{Computação de Alto Desempenho}\index{HPC,GPGPU}\label{GPGPU}
    
    Computação de Alto Desempenho (\textit{High Performance Computing} - HPC) designa sistemas de alta capacidade de processamento
e armazenamento de dados montados especificamente resolver grandes problemas científicos, para os quais computadores pessoais não
são o suficiente. Esses sistemas variam em tamanho, poder computacional e capacidade de armazenamento. Os mais famosos,
conhecido como Supercomputadores, são máquinas montadas especialmente para resolver um único problema, ou um grupo
especifico de problemas, e tem em sua composição milhares de processadores. Porém existem instâncias mais simples de 
\textit{HPC}, onde um sistema é montado a partir de um \textit{Cluster} de computadores pessoais.

    No inicio dos anos 2000, com o inicio do suporte de operações de ponto flutuante, ainda que emuladas por software, 
e com o surgimento de um \textit{shaders} programável, as Unidades de Processamento Gráfico 
(\textit{Graphic Processing Units} - GPU) começaram a ser usadas para executar código de natureza mais genérica.
Chamamos a aplicação de GPUs na solução de problemas computacionais, fora da área de computação gráfica, 
de \textit{General-purpose computing on graphics processing units}, ou GPGPU. Com o alto custo beneficio que as GPUs 
trazem e seu alto poder de realizar processamento paralelo, arquiteturas de HPC começaram a aparecer utilizando não a 
CPU, mas sim a GPU como principal carro chefe de processamento.

\subsection{Unidade de Processamento Gráfico}
    A GPU nasceu da necessidade de renderizar cenas complexas, mantendo uma taxa de quadros por segundos
aceitável para o usuário, em tempo real. Ela foi projetada para executar uma sequência fixa de passos que transformam
os dados da cena em objetos virtuais na tela. A sequência de passos se assemelha a uma linha de montagem de fabricas,
onde objetos são montados parte por parte de forma sequencial. Chamamos essa sequência de \textit{Pipeline} gráfico 
(ver figura \ref{fig:pipeline}), e a GPU é construída para que cada passo dele seja mapeado para uma ou mais partes do 
seu hardware.

    É comum cenas conterem objetos complexos, compostos de milhões de triângulos, que passarão, um por um, pelo
\textit{Pipeline} gráfico. Para acelerar o processo de renderização, as GPUs seguem a arquitetura de Instrução Única,
Múltiplos Dados (\textit{Single Instruction, Multiple Data} - SIMD). Como o nome já diz, essa arquitetura permite que 
a mesma instrução seja executada várias vezes em paralelo utilizando instâncias de dados diferentes. A figura 
\ref{fig:simd} mostra a implementação do \textit{Pipeline} utilizando a arquitetura SIMD no hardware da GPU.
    
    Para implementar de maneira esse paradigma, a GPU é composta de vários hardwares específicos. Nela existe um 
escalonador para \textit{threads} implementado em hardware. Ele é responsável por escalonar as \textit{threads} que serão
executadas nos \textit{Streaming Multiprocessors} (SM). Um SM é um conjunto de vários processadores, um pequeno bloco de
memória própria, um cache de instruções e 8 unidades de funções gráficas.

    O código que será executado em cada processador é chamado de \textbf{kernel}. Ao executar um kernel na GPU, o 
hardware criará \textit{threads}, cada uma delas executando o mesmo código, mas com dados diferentes. Nas placas NVIDIA as \textit{threads} 
são agrupadas em blocos, e esses blocos são escalonados para cada SM. Depois, todas as \textit{threads} dentro de um bloco são 
divididas em pequenos grupos chamados de \textbf{warp}, e cada warp é executado paralelamente dentro do 
mesmo SM para qual o bloco foi escalonado. Existe um limite para a quantidade de \textit{threads} escalonadas para execução
dentro de um SM, que é definida pelos recursos que cada \textit{thread} consome. Por exemplo, não há como executar 10 \textit{threads}
que consomem 10 registradores cada em um SM com 90 registradores.

    A memória da GPU é limitada em relação à da CPU. GPUs tem, em média, 4GB
de memória, enquanto CPUs tem acesso a, no minimo, 8GB. O acesso a um mesmo bloco de memória é concorrente, mas ao utilizar caches e leitura 
ou escritas em conjunto podemos minimizar a taxa com que leituras ou escritas conflitantes são feitas. Mas ainda sim é 
necessário atenção ao escrever um kernel. Dada a estrutura do hardware da GPU, é melhor deixar \textit{threads} que façam 
operações sobre posições de memória próximas no mesmo SM, assim elas podem utilizar a memória compartilhada do mesmo, e 
elas podem requisitar em conjunto um mesmo bloco da memória principal, se necessário.

    Outro fator limitante é a transferência de dados da memória principal do computador para a memória 
principal da GPU. A transmissão é feita por um barramento PCI Express, com velocidades de até 16GB/s ( dado que o
barramento seja utilizado somente pela GPU ). Essa transmissão é a parte mais lenta de todo o
processo de execução na GPU e dado isso, em alguns casos é mais viável executar na GPU um pedaço do seu programa que 
seria executado na CPU do que retornar os dados computados na GPU para a CPU, executar esse pedaço especifico, e 
passá-los de volta para a GPU para mais operações e novamente retornar esses dados para a CPU no final, passando duas 
vezes a mais pelo PCI Express.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figuras/pipeline.jpg}
    \caption{\textit{Pipeline} do OpenGL 4.x, por \citep{pipeline}. Todos os passos marcados pela cor amarela podem
    ser reprogramados para serem utilziados por aplicações GPGPU. (Modificada)}
    \label{fig:pipeline}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figuras/simd.jpg}
    \caption{Arquitetura da GPU SIMD, por \citep{blythe2008rise}.}
    \label{fig:simd}
\end{figure}

\subsection{CUDA}\index{CUDA}
\textit{Compute Unified Device Architecture}, definida pela (CUDA) é uma arquitetura de programação para GPUs criada 
pela ~\cite{nvidia2007compute}.
Ele adiciona suas diretrizes para as linguagens C, C++, FORTRAN e Java, permitindo que elas usem a GPU.
Esse trabalho usa o CUDA junto com a linguagem C.
A versão 1.0 do CUDA foi disponibilizada no inicio de 2007. Atualmente só existe um compilador para CUDA, o nvcc,
e ele só da suporte para GPUs NVIDIA.

Para uma função executar na GPU ela precisa ser invocada de um programa da CPU. Chamamos esse programa de \textit{Host}
e a GPU onde o kernel irá executar de \textit{Device}.

O CUDA implementa um conjunto virtual de instruções e memória, tornando os programas retroativos. O compilador
primeiro compila o código em C para um intermediário, chamado de PTX, que depois será convertido em linguagem
de máquina. Na conversão do PTX para linguagem de máquina o compilador verifica quais instruções o \textit{device}
suporta e converte o código para usar as instruções corretas.
Para obter o maior desempenho possível, é importante saber para qual versão o código final será compilado, 
pois na passagem do código de uma versão maior para uma menor não existe a garantia que o algoritmo seguira as mesmas instruções, 
o compilador pode mudar um conjunto de instruções para outro menos eficiente, ou em alguns casos, algumas instruções não existem em
versões mais antigas do hardware.

\subsubsection{Modelo de Plataforma}
A inicialização dos recursos que o CUDA necessita para a comunicação com a GPU é feita no background da
aplicação no momento da primeira chamada de alguma das diretivas do CUDA. Essa primeira diretiva terá um
tempo maior de execução que chamadas subsequentes a mesma diretiva. Na inicialização o CUDA identifica
os \textit{devices} existentes e escolhe um deles para ser o responsável pelas execuções posteriores.

O próximo passo é a alocação de memória no \textit{device}. As operações de leitura de memória de um kernel são feitas somente
na memória de um \textit{device}. A alocação dessa memória é feita pelo \textit{host}, usando \verb#cudaMalloc()#. 
Para copiar a memória do \textit{host} para o \textit{device} ou vice-versa,
\verb#cudaMemcpy()# é usada. Para liberar o espaço alocado após a execução basta usar o \verb#cudaFree()#.
Todas essas diretivas recebem um ponteiro do \textit{host}, usado para o controle sobre qual posição da memória está sendo
operado em cada operação.

O CUDA dá suporte a alocação de vetores em duas ou três dimensões através de: \verb#cudaMallocPitch()# e 
\verb#cudaMalloc3D()#, respectivamente. É necessário usar as modificações dos comandos \verb#Memcpy# para
duas ou três dimensões também, que são: \verb#cudaMemcpy2D()#, \verb#cudaMemcpy3D()#.

\subsubsection{Modelo de Programação}
Um kernel no CUDA é uma função C que será executada paralelamente $n$ vezes em $n$ \textit{threads} diferentes na GPU. Um kernel pode ser
definido em qualquer lugar do seu código, usando a declaração \verb#__global__# do lado esquerdo do tipo de retorno do kernel.
Para invocar um kernel, o \textit{host} faz a chamada de uma função com a sintaxe parecida com o C, mas usa uma configuração de
execução definida pelo CUDA, que usa a sintaxe \verb#<<<...>>># junto da chamada da função. Os parâmetros da configuração são
o número de blocos de \textit{threads} e o número de \textit{threads} por blocos. Para somar dois vetores de tamanho M e guardar o resultado num
outro vetor, o código é o seguinte:

\begin{lstlisting}
  __global__ void MatrixMulti ( float* a, float* b, float* c) { 
    int i = threadIdx.x;
    a[i] = b[i] + c[i];        
  }
                            
  int main () {               
    ...                       
    VecAdd<<<1,M>>>(a, b, c)  
    ...                       
  }                                 
\end{lstlisting}

No kernel acima, a linha \verb#int i = threadIdx.x# atribui a variável i o valor do índice da \textit{thread} atual na primeira dimensão. 
A estrutura \verb#threadIdx# é um vetor de 3 dimensões, logo as \textit{threads} podem ser organizadas em 1, 2 ou 3 dimensões dentro de um
\textit{device}. As \textit{threads} são organizadas por blocos. Cada bloco tem dimensões maleáveis, mas as GPUs atuais limitam para 1024 o 
número máximo de \textit{threads} por blocos. Cada bloco é lançado para execução em um processador diferente. Blocos são organizados em 
grids, que tem seu tamanho configurado na chamada o kernel, bem como o tamanho de cada bloco. No nosso exemplo acima, na linha
\verb#VecAdd<<<1,M>>>(a,b,c)#, o 1 determina o número de blocos e o M o número de \textit{threads} por bloco.

O CUDA supõem que todos os blocos podem ser executados de maneira independende, ou seja, eles podem executar tanto paralelamente
quanto sequencialmente. Com isso, é possivel que o desempenho do código aumente em GPUs com mais processadores, sem que o programador
tenha que modificar o código.

O CUDA sabe qual instruções ele pode executar dentro de um \textit{device} baseando-se no seu Compute Capability 
(Capacidade Computacional). A Compute Capability de um \textit{device} são dois números, um que representa a arquitetura do 
\textit{device}, e outro que representa melhorias numa arquitetura.
A arquitetura \textit{Tesla}, a primeira da NVIDIA a dar suporte a GPGPU, tem Compute Capability 1.x, a seguinte, a \textit{Tesla},
tem 2.x e a atual, a \textit{Kepler}, tem 3.x. Dentro de cada arquitetura, podem existir melhorias nas instruções, que são
refletidas no número após o ponto, ou seja, uma placa com Compute Capability 2.1 tem instruções que uma 2.0 não tem.

\subsubsection{Hierarquia de Memória}
No CUDA, a memoria é separada logicamente em 4 locais:

\begin{itemize}
  \item Registradores - Toda variável de uma \textit{thread} fica em registradores.
  \item Memória Local - Memória acessível por cada \textit{thread} separadamente, mas de uso pouco provável. Ela só é usada se
          não existe mais espaço nos registradores ou se o compilador não ter certeza sobre o tamanho de um vetor.
  \item Memória Compartilhada - Cada bloco de \textit{threads} tem uma memória compartilhada. A memória compartilhada é separada em
          pequenos blocos independentes. Se uma requisição de leitura tem n endereços em n blocos diferentes, o tempo de leitura
          desses n endereços é igual ao tempo de leitura de 1 endereço. Caso duas leituras caiam no mesmo bloco, elas serão
          serializadas. A memória compartilhada fica em chips dentro dos SMs, logo seu acesso é mais rápido do que o acesso a
          memória global.
  \item Memória Global - A memória global é acessivel por qualquer bloco em execução em um \textit{device}. A memoria global não é
          apagada após a execução de um kernel, então chamadas subsequentes de um mesmo kernel simplesmente leem os resultados
          da memória global. Existe um pedaço da memória global reservada para valores constantes do programa.
\end{itemize}

Por padrão, o compilador do CUDA cuida do gerenciamento da memória, ou seja, ele é o responsável por distribuir os dados 
entre os locais diferentes de memória. O programador pode dar dicas para o compilador usando qualificadores indicando o local
que ele quer que aquele elemento fique na memória. Os possiveis qualificadores são:
\begin{itemize}
  \item \verb#__device__# Fica na memória global.
  \item \verb#__constant__#   Fica na area constante da memória global.
  \item \verb#__shared__# Fica na memória compartilhada das \textit{threads}.
  \item \verb#__restrict__# Indica para o compilador que todos os ponteiros com esse qualificador apontam para locais diferentes
                            da memória. Isso é importante pois o compilador pode fazer otimizações com o código sabendo dessa informação.   
\end{itemize}

GPUs com Compute Cabapility maior ou igual a 2.0 podem alocar memória dentro do \textit{device} em tempo de execução.

%% ------------------------------------------------------------------------- %%
%% ------------------------------------------------------------------------- %%
\section{Algoritmos de Registro}\label{sec:algReg}
    Escolhemos dois algoritmos com base na facilidade deles em adotar uma paralelização seguindo o modelo SIMD.
Falaremos mais sobre eles abaixo.

%% ------------------------------------------------------------------------- %%
\subsection{\textit{Demons}}\index{Demons}
    O \textit{Demons} foi proposto por \cite{thirion1995fast}. Diferentemente de grande parte dos algoritmos de registro,
ele não segue exatamente os passos descritos acima. Ele tem como base o modelo de atratores, que dado dois conjuntos de pontos
em cada uma das imagens, os pontos da imagem Alvo são atraidos para seus pares na imagem Referência utilizando alguma métrica.
A métrica mais básica de atração é a de vizinhos próximos, que leva cada ponto ao ponto mais próximo da imagem de 
referência, mas técnicas mais elaboradas como a similaridade de curvatura ou intensidade podem ser utilizadas para 
aumentar a acurácia. Os pontos da imagem alvo então movimentam a imagem até que eles encontrem algum ponto da imagem
de referência.

    O \textit{Demons} aplica uma dimensão de informação a mais ao modelo de atratores, acrescentando a cada ponto uma direção
associada ao gradiente da imagem. Um exemplo pode ser visto na imagem \ref{fig:demons}. 
Chamamos cada um desses pontos de \textit{Demon}. Com essa informação o algoritmo é capaz
de identificar pontos dentro e fora do modelo gerado a partir dos \textit{Demons} e direcionar a força para empurrá-los ou
atraí-los, respectivamente. Para obtermos o melhor resultado possível adotamos um \textit{Demon} por pixel/voxel.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figuras/demons.jpg}
    \caption{A primeira linha demonstra o sistema de atratores, enquanto a segunda o Demons, por \citep{thirion1995fast}}
    \label{fig:demons}
\end{figure}

\subsubsection{Aproximação matemática da transformação}
    O \textit{Demons} supõe que a transformação não muda a função de densidade, ou seja, ela só movimenta os pixels e não muda
suas intensidades. A equação seguinte resume isso:
\begin{align}
    i(x(t),y(t),z(t)) = const, \\
\end{align}
    onde $i$ é a intensidade da imagem na posição $x(t),y(t),z(t)$. Derivando (1) temos:
\begin{align}
    \frac{\partial i}{\partial x} \frac{\partial x}{\partial t} +
    \frac{\partial i}{\partial y} \frac{\partial y}{\partial t} = - \frac{\partial i}{\partial t}
\end{align}
    Supondo que as duas imagens que temos diferem de uma unidade de tempo $\partial i/\partial t = 
r-a$, \textit{r} e \textit{a} as intensidades de R e A respectivamente e que a velocidade instantânea 
$\vec{v} = (dx/dt,dy/dt)$ é aplicada a cada pixel para movê-lo de A para R, chegamos a equação:
\begin{align}
    \vec{v}*\vec{\nabla}r = a - r, \ \text{onde} \ \vec{\nabla} r \ \text{é o gradiente de R}
\end{align}
    O inverso da transformação é aproximado por $\vec{v}$. Porém essa equação é instável em relação a norma de $\nabla 
r$. Se a sua norma for muito pequena o \textit{Demon} em questão é levado para o infinito em alguma direção. Podemos levar em 
conta a diferença dos pixeis de R e A para normalizar a equação (4), obtendo a forma final do \textit{Demons}:
\begin{equation}
    \vec{v} = \frac{\vec{\nabla}r * (a - r)}{\vec{\nabla}r^2 * (a - r)^2}
\end{equation}

\subsubsection{Implementação}
    Como a formula (5) é degenerada, ou seja, não é possivel encontrar uma solução analiticamente para ela,
não podemos calcular o valor de $\vec{v}$ sem utilizar algum artificio. Para tal,
utilizaremos um algoritmo iterativo. Esse algoritmo recebe como entrada as imagens R e A e um campo vetorial
com as dimensões de A que contém uma aproximação da transformação aplicada, esse campo pode ser zero. 
Cada iteração realiza 3 passos:
\begin{enumerate}
    \item Para cada \textit{Demon} em $A_i$, calculamos $\vec{v_i}$, criando um novo campo vetorial $V_i$
    \item Aplicamos um filtro Gaussiano para retirar o ruído introduzido pelo processo em $V_i$
    \item Aplicamos $V_i$ em $A$ para obter $A_{i+1}$;
\end{enumerate}
    Esse processo é feito até que $A_i$ convirja à $R$. É importante lembrar que é necessário a
utilização de um algoritmo de interpolação, já que é extremamente provável que o vetor $\vec{v}$
leve os pontos para posições não inteiras. A interpolação trilinear já é suficiente para tal.

\subsubsection{\textit{Demons} Simétrico}\index{Demons Simétrico}
    O método acima é conhecido como \textit{Demons} Assimétrico, pois ele só utiliza informações vindas
da imagem referência. No mesmo artigo, Thirion propõe um outro método, conhecido como Simétrico.
Nele a equação para o cálculo de $\vec{v}$ leva o gradiente das imagens $A_i$. Ele obtém resultados
melhores ao custo do cálculo do gradiente de $A_i$ em toda iteração. Sua fórmula é dada por:
\begin{align}\label{math:demons}
    \vec{v} = \frac{4(a - r)*\vec{\nabla}r|\vec{\nabla}r||\vec{\nabla}a|}
                    {(\vec{\nabla}r+\vec{\nabla}a)^2*(\vec{\nabla}r^2 + \vec{\nabla}a^2 + 2(a - r)^2)}
\end{align}

\subsubsection{Aceleração do \textit{Demons}}
    O primeiro passo do algoritmo iterativo pode ser acelerado utilizando a arquitetura SIMD. O calculo de um dos vetores
depende do gradiente $\vec{\nabla}r$ e da diferença entre as intensidades da imagem Alvo e Referência $(a - r)$, logo
todos os passos podem ser realizados em paralelo sem perda de desempenho. Tanto a aplicação do filtro gaussiano como
a aplicação do campot vetorial $V$ também podem ser adaptados para a SIMD, pelo mesmo motivo apresentado anteriormente.
Devemos tomar cuidado para garantir que os passos sejam executadas de forma sequencial, ou seja, nenhum pixel deve começar
a execução do passo 2 antes que todos tenham executado o passo 1.

%% ------------------------------------------------------------------------- %%
\subsection{Thin Plate Splines}\index{TPS}
    O Thin Plate Splines (TPS) segue mais à risca os passos gerais de um algoritmo de registro. Ele utiliza
características para criar uma função de interpolação que é utilizada para criar a imagem registrada a partir
da imagem referência. Vários algoritmos podem ser utilizados para adquirir as características que serão usadas
pelo TPS, mas não abordaremos esse assunto pois ele foge do escopo do trabalho. Assumimos no inicio da sua
execução que 2 conjuntos de características existem, um para cada imagem, e que uma correspondência entre
eles já é estabelecida.

    Dados as características na imagem referência $(x_i,y_i, i=1,..,n)$ e na imagem alvo $(X_i,Y_i, i=1,..,n)$
o TPS cria uma função que mapeia exatamente cada característica da imagem referência na sua
correspondente na imagem alvo e que é capaz de interpolar os pontos restantes para a imagem final. Para realizar
essa tarefa é utilizada uma função que define uma superfície que sofre a ação de pesos centrados nas
características da imagem referência. A superfície é definida pela seguinte equação, escrita por \cite{bookstein1989principal}:

\begin{align}\label{math:tps}
    f(x,y) = A_0 + A_1x + A_2y + \sum_{i=0}^n F_i r_i^2 ln r_i^2
\end{align}
Onde $r_i^2 = (x-x_i)^2 + (y-y_i)^2 + d^2$, $d$ é um fator de rigidez da superfície, quanto mais próximo de 
zero $d$ é mais a superfície sofre ação dos pontos de controle, e os pontos $(x_i, y_i)$ são os pontos de controle.

    O TPS deve então determinar os valores das variáveis $A_0, A_1, A_2$ e dos $F_i$. 
Isso é feito através do sistema linear:

\begin{align}
\begin{split}
    \sum_{i=1}^n F_i &= 0 \\
    \sum_{i=1}^n F_ix &= 0 \\
    \sum_{i=1}^n F_iy &= 0 \\
    f(x_1,y_1) &= A_0 + A_1x + A_2y + \sum_{i=0}^n F_i r_{i1}^2 ln r_{i1}^2 \\
    \vdots \\
    f(x_n,y_n) &= A_0 + A_1x + A_2y + \sum_{i=0}^n F_i r_{in}^2 ln r_{in}^2
\end{split}
\end{align}

A equação $\sum_{i=1}^n F_i = 0$ faz com que a soma dos pesos aplicados a superfície seja zero, fazendo com que
ele não se mova. As equações $\sum_{i=1}^n F_ix = 0$ e $\sum_{i=1}^n F_iy = 0$ garantem que a superfície não vai girar.

    Esse sistema deve ser resolvido duas vezes, uma para $f(x,y) = X$ e outra para $g(x,y) = Y$. Com todas as variáveis
encontradas, podemos aplicar as funções de interpolação para desenhar a imagem final.

\subsubsection{Aceleração do Thin Plate Splines}

    O primeiro passo para acelerar o TPS é utilizar algoritmos para resolver o sistema linear diretamente na GPU, o que
não é dificil dado que a matriz que representa o sistema sempre é simetrica com uma diagonal de zeros por construção. O
próximo passo para realizar a acelereção do TPS é criar dois vetores que guardam todos os valores possíveis de $(x-x^i)^2$
e $(y-y^i)^2$. O uso desses vetores diminui o número de operações necessárias de $n_l*n_c$ para $n_l+n_c$. Da maneira
original, a operação $(x-x^i)^2$ é repetida $n_c$ vezes para cada coluna, já com o uso dos vetores esse valor é calculado
uma única vez e acessado toda vez que ele é necessário.

% Colocar outros algoritmos de regitro %